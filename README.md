# cuda_learning 入门
记录学习Cuda编程的项目

## One Day:

任务清单：配置GPU环境以及创建GPU版的Hello world!

### 一、配置GPU编程环境

主要参考[这篇文章](https://blog.csdn.net/chen565884393/article/details/127905428)

首先检查N卡的驱动，并安装对应的CUDA，然后安装CUDNN

因为我的是GTX1060，所以只能支持CUDA11.4，注意这里我才过坑，安装了11.5,11.6版本在后面对cu程序进行编译的时候会报错，因此要注意显卡能支持的最高CUDA版本，然后根据CUDA版本确定 Visual Studio的版本，

因为官网默认下载最新版本，实际上是不支持古早的CUDA版本的，因此可以根据上面文章提到连接查询官方CUDA支持的VS范围，**注意此处的版本十分重要，如果版本错误会导致后面编译失败**

我最开始下载的是VS 2022 community 的版本，即使在里面选择安装2019,2017的编译器仍然会报错误，提示头文件找不到，或者版本的问题，改回2019版本的就没问题了。

### 二、Hello world

对于GPU编程主要分为两部分，一部分是主机(host)，另一部分则是设备(Device)

主机代码主要在CPU上运行，设备代码则是在GPU上运行完成

我们可以在CPU上运行逻辑分支，然后调用GPU进行计算，但这里GPU的计算与主机是异步的。

调用GPU的函数之后，CPU的控制权依然会往下运行，如果CPU后面的代码可以主动调用同步操作`cudaDeviceSynchronize`函数来同步，这里CPU会阻塞等待GPU完成计算。

同时也可以调用`cudaMemcpy`在主机和设备间拷贝数据时，这里CPU也会阻塞来隐式同步数据。

## Two Day:

GPU编程主要语法与C语言类似，主要是多了一些特殊标识符

$$
\begin{array}{c|c|c|c}
\hline
限定符 & 执行 & 调用 & 备注\\
\_\_{global}\_\_ & 设备端执行 & 主机调用，也可以从算力3以上的设备中调用 & 返回类型必须是void \\
\_\_{device}\_\_ & 设备端执行 & 仅能从设备中调用  \\
\_\_{host}\_\_ & 主机端执行 & 仅能从主机调用 & 可省略 \\ 
\hline
\end{array}
$$

### 代码要点

对于GPU调用时，其线程创建模型为两个部分，第一个部分叫网格(grid),第二个叫线程块(block),线程块包含了N个线程，结构图如下：

```
                                            每一个Grid
----------------------------      -------------------------------
|        |        |        |      |         |         |         |
| grid1  | grid2  | grid3  |      | block1  | block2  | block3  |
|--------------------------|      |-----------------------------|
|        |        |        |      |         |         |         |
|        |        |        | -->  |         |         |         |
|--------------------------|      |-----------------------------|
|        |        |        |      |         |         |         |
|        |        |        |      |         |         |         |
----------------------------      -------------------------------
```
Grid和Block都由一个三维坐标标识(dim3)，每个`(x,y,z)` 唯一确定一个网格或者一个块。

因此我们可以创建一个维度`(3,3,3)`的网格，每个网格又是一个维度为`(4,4,4)`的线程块。因此总线程数为 $3^3(网格数) * 4^3(线程数)$

1. 网格的维度由线程块的数量来表示
2. 线程块的维度由线程数来表示   

在代码`MatrixSum`中：
```
dim3 block = (16);
dim3 grid = ((matrix_len + block.x - 1) / block.x);
```
这里计算所需要网格数的代码`((matrix_len + block.x - 1) / block.x)` 是为了让所有的数据能被网格所包括，因此加上`block.x-1`,这也是为了规避除法的向下取整，导致无法囊括到所有数据。

```
------------------------------------------------------------
| data1 | data2 |       |       |       |       |       |  |
|       |       |       |       |       |       |       |  |
------------------------------------------------------------
                                                            ^
                                                            |
-----------------------------------------------------------------
| block1| block2|       |       |       |       |       |       |
|       |       |       |       |       |       |       |       |
-----------------------------------------------------------------
    1       2       3       4       5       6       7       8
```

# GPU优化

## 3.1GPU架构

GPU有多个流式多处理器(SM)，执行时每一个SM分配多个线程块，SM分配的线程块数由其中的资源来决定

CUDA中采用单指令多线程架构(`SIMT`)，每32个线程为一组称为线程束(`warp`)
线程束中的所有线程同时执行相同的指令

每一个SM都将分配给他的所有线程块的线程按照线程束进行划分，其中一个线程块被分配到一个SM后会一直存在其中，直到完成线程任务

```     
               -------    -------------
           |——>|warp | -->| 32 thread |  --|     ---------
           |   -------    -------------    |---> | block |
-------    |   -------    -------------    |     ---------
| SM  |  --|——>|warp | -->| 32 thread |  --|
-------    |   -------    -------------
           |   -------    -------------
           |——>|warp | -->| 32 thread |
               -------    -------------
```

**warp才是SM上的执行单位**，因此不同线程束之间的进度可能会不一致，也就会导致线程块之间不同的线程以不同的速度前进。

编译指令：
```
nvcc -O3 按照级别3来优化主机代码
nvcc -G -g 生成Debug信息
```

## 3.2线程束

在硬件上线程都是一维排开，尽管线程块可能是1,2,3维。同时根据`threadIdx.x`的连续值来划分线程束，对于多维的线程块，同样可以根据下列公式转换成一维排列。

一维线程 `(x)`：
$$
thread_{i} = threadIdx.x
$$

二维线程 `(x,y)`：
$$
thread_{i} = threadIdx.x + threadIdx.y \times blockDim.x
$$

三维线程块 `(x,y,z)`
$$
thread_{i} = threadIdx.z \times  (blockDim.x \times blockDim.y) + threadIdx.y \times blockDim.x + threadIdx.x
$$

可以看到线程坐标按照 x为内部维度，y作为外部维度，z作为最外面的维度进行递增。

注意到：$一个线程块中的线程束的数量 = 向上取整({一个线程块中的线程数量 \over 线程束大小})$

因此**线程束不会跨线程块进行分配**，如果当一个线程块的线程数不是线程束大小的偶数倍会造成资源浪费。并会影响线程束的调用，从而影响效率

### 3.2.1线程束分化

GPU对于带有逻辑判断的分支语句，例如`if...else...`并没有复杂的分支预测的能力。*但对于同一个线程束中所有线程必须在同一周期中执行相同的指令*，因此分支语句会导致一个线程束中不同的线程走到不同的分支语句，这就是线程束的分化。

**线程束的分化会明显导致性能下降**

对于代码：`chapter3/branch.cu`，关闭编译器的分支预测优化功能进行运行测试。
编译：`nvcc -g -G branch.cu -o branch`

运行：`sudo ./ncu --metrics smsp__sass_average_branch_targets_threads_uniform.pct branch`

可以看到在RTX3050上分支效率结果为：
```
mathKernal2:80%
mathKernal3:100%
mathKernal4:71.43%
```
线程束级别的分支效率几乎没有分化的分支

每个线程束的资源都保存在SM单元中，进行线程束切换的时候不会产生性能损失

同时每个SM内核只有固定数量的共享内存和寄存器组，
因此每个线程消耗的寄存器越少，SM能同时处理的线程束越多
每个线程块消耗的共享内存越多，SM能同时处理的线程块就越少

### 3.2.2 延迟隐藏
指令发出和完成这段时钟周期被称为指令延迟

在指令延迟这段时间中，每个调度器都有一个符合条件的线程束可用于执行，那么就能隐藏这段延迟（流水线）

延迟分为：算术指令延迟/内存指令延迟

隐藏延迟所需要的活跃线程束数量可以由如下公式进行计算：$线程束数量 = 线程束的延迟\times吞吐量$

吞吐量由SM中每个周期的操作数确定，SM中以线程束为执行单位，因此一个周期会同时有线程束大小的操作执行(warpSize)，上述式子换算成操作单位可以表示成：$操作数 = 指令延迟\times吞吐量$

吞吐量的单位为：操作/周期
指令延迟单位为：周期

根据操作数的需要同时很容易反推需要多少个线程，线程束以及每个SM至少多少个线程束。

同时不要忽略SM的线程束数量同时也受限于硬件资源

### 3.2.3 占用率

占用率的计算公式如下：
$$
占用率 = {活跃线程束 \over 最大线程束}
$$

最大线程束数量可以在设备信息中查询，通过`cudaGetDeviceProperties`获取设备参数信息的结构体，`maxThreadsPerMultiProcessor/warpSize` 可以得到最大的线程束数量

例如本机为`NVIDIA GeForce RTX 3050 Laptop GPU`,其中最大的线程束数量为`maxThreadsPerMultiProcessor/warpSize = 1536/32 = 48`

可以对编译器添加参数`--ptxas-options=-v`
或在CMakeLists.txt中添加`set(CUDA_NVCC_FLAGS --ptxas-options=-v)` 来查看每个核函数使用了多少个寄存器以及共享内存的资源。

提高利用率我们需要设置合适的线程块配置。过大过小都会影响资源的利用率。

小线程块：会在所有资源被充分利用之前到达SM的线程束数量的限制

大线程块：会导致每个SM中每个线程可用的硬件资源过少

网格和线程块大小划分准则：

1. 保持每个块中的线程是**线程束大小的倍数**
2. 避免块太小，每个块至少有表128或者256个线程
3. 根据内核资源调整块的大小
4. 块的数量要远多于SM的数量，达到足够的并行

### 3.2.4 同步

线程块之间的同步: `__device void __syncthreads()`
系统级同步：`cudaDevicesSynchronize()`

线程块是以线程束为单位执行，因此同一个线程块中的不同线程束会处于不同的程序点，所以提供`__syncthreads`来同步块中的所有线程

同步之前线程块中的所有线程产生的共享内存或全局内存的修改操作等，在同步后会对线程块中的所有线程可见，并且是安全的。**因此可用于线程间的通讯**



## 3.3 性能指标

老版本cuda可以使用nvprof来查看程序运行的各种指标,现在逐渐替换成ncu工具来检查程序运行的性能指标。

更多参数对照可以参考官方提供的CUDA手册`《NSIGHT COMPUTE COMMAND LINE INTERFACE》` [Ref:](https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvprof-guide)


### 3.3.1 SM占用率

```
nvprof --metrics achieved_occupancy ./xxx
ncu --metrics sm__warps_active.avg.pct_of_peak_sustained_active ./xxx
```
该指标越高越好

核函数运行时间
```
nvprof ./xxx
nsys nvprof ./xxx
```

在矩阵求和的例子中，不同参数下SM占用率和耗时分别为：
```
(32,32):53.24%  22.10ms
(32,16):70.08%  21.60ms
(16,32):73.10%  21.04ms
(16,16):78.04%  21.19ms
```

从上面结果可见第二种比第一种有更多的块，有着更好性能，但第四中比第三种也有更多的块，但性能并没有更好的提升，虽然SM占用率较高

### 3.3.2 内存读取效率

```
./ncu --metrics l1tex__t_bytes_pipe_lsu_mem_global_op_ld.sum.per_second ./xxx
```

可以看到结果如下：
```
(32,32):78.99 Gb/s 
(32,16):89.97 Gb/s
(16,32):90.65 Gb/s
(16,16):91.21 Gb/s
```
其中第四中具有最高的内存读取效率，但运行时间并没有第三种情况快，所以高内存读取效率并不代表着有最好的性能

### 3.3.3 全局加载效率

```
./ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./xxx
```
可以看到结果如下：
```
(32,32):100%
(32,16):100%
(16,32):100%
(16,16):100%
```

我们可以结合上述三个指标来判断最佳的块组合

## 3.4 归约问题

对于一个数组求和或者求最大值的问题而言，使用CPU顺序求和在数据量比较大的情况下是比较复杂的，时间复杂度`O(n)`,因此可以考虑使用并行归约来进行求解。

并行归约的主要思想是，对于一个线程块划分数据区域，每个数据块处理一个区域，然后逐层将数据结果汇总

参见代码:[reduceInteger.cu:matrixSum](/chapter3/reduceInteger.cu)

方法`matrixSum`主要方式是如图所示：
```
            -------------------------------------
data:       |  0  |  1  |  2  |  3  |  4  |  5  |
            -------------------------------------
               |     |     |     |     |     |
            -------------------------------------
threadId:   |  0  | (1) |  2  | (3) |  4  | (5) |
            -------------------------------------
               |     |     |     |     |     |   
               -------     -------     ------- 
               |           |           |
            -------------------------------------
data:       |  0  |     |  2  |     |  4  |     |
            -------------------------------------
```

其中偶数线程负责进行相邻步长的相加,奇数线程则不进行处理。`matrixSumNeighbored` 方法则是在线程的处理上进行了排序整合

方法`matrixSumNeighbored`主要方式是如图所示：
```
            -------------------------------------
data:       |  0  |  1  |  2  |  3  |  4  |  5  |
            -------------------------------------
               |     |     |     |     |     |
            -------------------------------------
threadId:   |  0  |     |  1  |     |  2  |     |
            -------------------------------------
               |     |     |     |     |     |   
               -------     -------     ------- 
               |           |           |
            -------------------------------------
data:       |  0  |     |  2  |     |  4  |     |
            -------------------------------------
```

使用相邻的线程分别间隔一个步长区处理不同的数据区域进行归并

这两种方法总线程数并没变，只是改变了活跃线程的排布，对于`512`个线程而言，第一种方法按照`32`划分线程束共有`16`个线程束.
每个线程束中有一半的线程处于非活跃状态，而第二种将活跃线程全部集中在前`8`个线程束中,由于线程束中每个线程执行的命令操作要保持一样，因此第一种方法会因为线程的分化影响性能。而第二种则完全避免了这种情况。

**所以确保线程束中减少线程分化有利于提高性能**

同第二种方法类似，`matrixSumInterleaved`使用交叉归约的方式进行求和。主要流程如下：
```
            -------------------------------------
data:       |  0  |  1  |  2  |  3  |  4  |  5  |
            -------------------------------------
               |     |     |     |     |     |
               -------------------     |     |
               |     |     |           |     |
               V     -------------------     |
                     |     |                 |
                     V     -------------------
                           |
                           V
            -------------------------------------
threadId:   |  0  |  2  |  3  |     |     |     |
            -------------------------------------
               |     |     |
            -------------------------------------
data:       |  0  |  1  |  2  |     |     |     |
            -------------------------------------
```

每个线程先按数据长度的一半进行求和处理，然后结果汇集到前半段，然后继续处理前半段数据进行求和。注意边界判断，每次只有小于步长的线程才进行计算。并且同方法二一样活跃线程集中在块的前半部分。

`__syncthreads`块内数据同步，每次加法计算完，确保每块其他线程完成计算。

这三种方法的SM利用率，内存加载速率以及全局加载率如下：
```
matrixSum            96.80%  91.14Gb/s 25.05%
matrixSumNeighbored  93.05% 191.70Gb/s 25.05%
matrixSumInterleaved 91.92%  59.95Gb/s 96.78%
```
从结果可以看到交错合并计算效率最高。

## 3.5 展开归约
展开归约是指在一个循环里将一次执行复制成多次的计算，这样可以将所有归约的次数继续缩短。
展开的次数称为展开因子

对上一节方法三进行更改，每个线程块处理两块数据内容。在进行块内合并之前，先进行块间数据累加，然后进行块内求和。可以看到效率更快。相比较与方法三拥有更高的内存加载速率。

**所以一个方法中有更多的独立内存操作，会导致内存有更高的吞吐量，从而性能提升**

展开归约的吞吐量和展开因子之间成正比。

### 3.5.1 线程内归约展开

对于方法四除了在块间进行归约展开以外，还能在块内归约展开。见方法五，将最后步长为`[8,4,2,1]`的结果展开求和，能使得合并效率更高。

### 3.5.2 完全展开归约
如果已知一个线程内的循环次数，可以手动将其完全展开，以扩大内存的吞吐量，提高执行速率

### 3.5.3 模板
对于一个cuda函数，我们可以使用模板添加一个变量，这个变量会在编译器编译的时候进行编译优化。使用方式如下：
```
template<data_type data_name> __global__ void function(){}
```

编译器在进行分支检查的时候，会自动删除关于`data_name`别且不满足条件的分支，以达到减少分支的目的。

## 3.6 动态并行

即在设备函数运行过程中，根据需要再次调用设备函数进行计算。典型的例子就是嵌套。